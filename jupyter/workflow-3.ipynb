{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "theme_style = \"darkgrid\"\n",
    "color_palette_style = \"deep\"\n",
    "palette = sns.color_palette(color_palette_style)\n",
    "\n",
    "# Set a warm-up phase (e.g., ignore the first 10 executions)\n",
    "warmup_executions = 200  # Adjust as needed\n",
    "\n",
    "days = [\n",
    "    \"2025-02-03\", \"2025-02-04\", \"2025-02-05\", \"2025-02-06\", \"2025-02-07\", \"2025-02-08\", \"2025-02-09\"\n",
    "]\n",
    "day_labels = [\n",
    "    \"Day 1\", \"Day 2\", \"Day 3\", \"Day 4\", \"Day 5\", \"Day 6\", \"Day 7\"\n",
    "]\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "folder_break_even = \"./experiment_plots/break-even-analysis\"\n",
    "file_ending = \".pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup directories\n",
    "os.makedirs(folder_break_even, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format minutes to time\n",
    "def format_minutes_to_time(minutes):\n",
    "    \"\"\"Convert decimal minutes to MM:SS format.\"\"\"\n",
    "    total_seconds = int(minutes * 60)\n",
    "    mm = total_seconds // 60\n",
    "    ss = total_seconds % 60\n",
    "    return f\"{mm:02}:{ss:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate break even day\n",
    "def calculate_break_even_day(baseline_df, optimized_df, warmup_executions=0):\n",
    "    # Sort and prepare data\n",
    "    baseline_df = baseline_df.sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "    optimized_df = optimized_df.sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    # Convert timestamp to datetime\n",
    "    baseline_df[\"timestamp\"] = pd.to_datetime(baseline_df[\"timestamp\"])\n",
    "    optimized_df[\"timestamp\"] = pd.to_datetime(optimized_df[\"timestamp\"])\n",
    "\n",
    "    # Compute cumulative execution time\n",
    "    baseline_df[\"cumulative_time\"] = baseline_df[\"execution_time\"].cumsum()\n",
    "    optimized_df[\"cumulative_time\"] = optimized_df[\"execution_time\"].cumsum()\n",
    "\n",
    "    # Compute elapsed time in minutes\n",
    "    baseline_df[\"duration_minutes\"] = (baseline_df[\"timestamp\"] - baseline_df[\"timestamp\"].min()).dt.total_seconds() / 60\n",
    "    optimized_df[\"duration_minutes\"] = (optimized_df[\"timestamp\"] - optimized_df[\"timestamp\"].min()).dt.total_seconds() / 60\n",
    "\n",
    "    # Trim the optimized function to match the length of the baseline function\n",
    "    optimized_df_trimmed = optimized_df.iloc[:len(baseline_df)].reset_index(drop=True)\n",
    "\n",
    "    # Find break-even point (ignore first N executions)\n",
    "    break_even_index = (\n",
    "        (optimized_df_trimmed[\"cumulative_time\"] < baseline_df[\"cumulative_time\"])\n",
    "        & (optimized_df_trimmed.index >= warmup_executions)\n",
    "    ).idxmax()\n",
    "\n",
    "    return baseline_df, optimized_df, break_even_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate break even each day\n",
    "def calculate_break_even_each_day():\n",
    "    optimized_df_list = []\n",
    "    baseline_df_list = []\n",
    "    # List to hold break-even points for each day\n",
    "    break_even_points = []\n",
    "    break_even_indices = []\n",
    "\n",
    "    # Loop through each day and calculate the break-even point\n",
    "    for day in days:\n",
    "        # Load the data for the current day\n",
    "        baseline_df = pd.read_csv(f\"./logs_analysis/{day}/execution_1/{day}-baselineFunction-logs.csv\")\n",
    "        optimized_df = pd.read_csv(f\"./logs_analysis/{day}/execution_1/{day}-optimizedFunction-logs.csv\")\n",
    "        \n",
    "        # Get the break-even point for this day\n",
    "        baseline_df, optimized_df, break_even_index = calculate_break_even_day(baseline_df, optimized_df, warmup_executions)\n",
    "\n",
    "        # Store the dataframes for later use\n",
    "        baseline_df_list.append(baseline_df)\n",
    "        optimized_df_list.append(optimized_df)\n",
    "\n",
    "        # Calculate the break-even time and append it to the list\n",
    "        break_even_time = baseline_df[\"duration_minutes\"].iloc[break_even_index]\n",
    "        break_even_points.append(break_even_time)\n",
    "        break_even_indices.append(break_even_index)\n",
    "\n",
    "    return optimized_df_list, baseline_df_list, break_even_points, break_even_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather grouped data\n",
    "def gather_optimized_all_days():\n",
    "    # prepare optimized data\n",
    "    df_list = []\n",
    "    for date in days:\n",
    "        file_path = f'./logs_analysis/{date}/execution_1/{date}-optimizedFunction-logs.csv'\n",
    "        if os.path.exists(file_path):  # Check if file exists to avoid errors\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert timestamp to datetime\n",
    "            df['duration_minutes'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60  # Normalize time\n",
    "            df['smoothed_execution_time'] = df['execution_time'].rolling(window=window_size).mean()\n",
    "\n",
    "            df_list.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    df_optimized_all_days = pd.concat(df_list, ignore_index=True)\n",
    "    # Sort the dataframe by duration_minutes to ensure proper rolling calculations\n",
    "    df_optimized_all_days = df_optimized_all_days.sort_values(by=['duration_minutes', 'duration_minutes'])\n",
    "    # Compute rolling median & std for optimized function\n",
    "    df_optimized_all_days['smoothed_median'] = df_optimized_all_days['execution_time'].rolling(window=window_size, center=True).median()\n",
    "    # Drop NaNs\n",
    "    df_optimized_all_days = df_optimized_all_days.dropna(subset=['smoothed_median'])\n",
    "\n",
    "    df_optimized_all_days = df_optimized_all_days.reset_index(drop=True)\n",
    "    return df_optimized_all_days\n",
    "\n",
    "def gather_baseline_all_days():\n",
    "    # prepare optimized data\n",
    "    df_list = []\n",
    "    for date in days:\n",
    "        file_path = f'./logs_analysis/{date}/execution_1/{date}-baselineFunction-logs.csv'\n",
    "        if os.path.exists(file_path):  # Check if file exists to avoid errors\n",
    "            df = pd.read_csv(file_path)\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert timestamp to datetime\n",
    "            df['duration_minutes'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60  # Normalize time\n",
    "            df['smoothed_execution_time'] = df['execution_time'].rolling(window=window_size).mean()\n",
    "\n",
    "            df_list.append(df)\n",
    "    \n",
    "    # Concatenate all dataframes\n",
    "    df_baseline_all_days = pd.concat(df_list, ignore_index=True)\n",
    "    # Sort the dataframe by duration_minutes to ensure proper rolling calculations\n",
    "    df_baseline_all_days = df_baseline_all_days.sort_values(by=['duration_minutes', 'duration_minutes'])\n",
    "    # Compute rolling median & std for optimized function\n",
    "    df_baseline_all_days['smoothed_median'] = df_baseline_all_days['execution_time'].rolling(window=window_size, center=True).median()\n",
    "    # Drop NaNs\n",
    "    df_baseline_all_days = df_baseline_all_days.dropna(subset=['smoothed_median'])\n",
    "\n",
    "    df_baseline_all_days = df_baseline_all_days.reset_index(drop=True)\n",
    "    return df_baseline_all_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ALL DAYS INDIVIDUALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average break-even time: 7.31 min\n",
      "Median break-even time: 6.70 min\n"
     ]
    }
   ],
   "source": [
    "# execute break even for all 7 days\n",
    "break_even_points = []\n",
    "\n",
    "# Loop through each day and calculate the break-even point\n",
    "for idx, day in enumerate(days):\n",
    "    # Load the data for the current day\n",
    "    baseline_df = pd.read_csv(f\"./logs_analysis/{day}/execution_1/{day}-baselineFunction-logs.csv\")\n",
    "    optimized_df = pd.read_csv(f\"./logs_analysis/{day}/execution_1/{day}-optimizedFunction-logs.csv\")\n",
    "\n",
    "    # Get the break-even point for this day\n",
    "    baseline_df, optimized_df, break_even_index = calculate_break_even_day(baseline_df, optimized_df, warmup_executions)\n",
    "\n",
    "    # Calculate the break-even time\n",
    "    break_even_time = baseline_df[\"duration_minutes\"].iloc[break_even_index]\n",
    "    break_even_points.append(break_even_time)\n",
    "\n",
    "    # Calculate the break-even time\n",
    "    break_even_time = baseline_df[\"duration_minutes\"].iloc[break_even_index]\n",
    "    break_even_points.append(break_even_time)\n",
    "\n",
    "\n",
    "# Calculate the average or median break-even point across all days\n",
    "avg_break_even = sum(break_even_points) / len(break_even_points)\n",
    "median_break_even = pd.Series(break_even_points).median()\n",
    "\n",
    "print(f\"Average break-even time: {avg_break_even:.2f} min\")\n",
    "print(f\"Median break-even time: {median_break_even:.2f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ALL DAYS GROUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(1.28449505), np.float64(2.4433270333333335), np.float64(6.05216795), np.float64(6.699711033333333), np.float64(7.483290533333333), np.float64(7.868791933333333), np.float64(19.3455568)]\n",
      "[200, 389, 938, 1023, 1206, 1230, 3093]\n",
      "Median run amount: 1023.0\n"
     ]
    }
   ],
   "source": [
    "# GROUPED FIGURE\n",
    "all_optimized_df = gather_optimized_all_days()\n",
    "all_baseline_df = gather_baseline_all_days()\n",
    "\n",
    "# Compute cumulative execution time\n",
    "all_optimized_df[\"cumulative_time\"] = all_optimized_df[\"execution_time\"].cumsum()\n",
    "all_baseline_df[\"cumulative_time\"] = all_baseline_df[\"execution_time\"].cumsum()\n",
    "\n",
    "\n",
    "# Calculate break evens for each day\n",
    "optimized_df_list, baseline_df_list, break_even_points, break_even_indices = calculate_break_even_each_day()\n",
    "# Calculate the average and median break-even times\n",
    "avg_break_even = sum(break_even_points) / len(break_even_points)\n",
    "median_break_even = pd.Series(break_even_points).median()\n",
    "median_run_amount = pd.Series(break_even_indices).median()\n",
    "\n",
    "\n",
    "print(sorted(break_even_points))\n",
    "print(sorted(break_even_indices))\n",
    "print(f\"Median run amount: {median_run_amount}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvJupyterBSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
