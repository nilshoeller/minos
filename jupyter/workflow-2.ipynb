{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "execution_count = 1  # Adjust as needed\n",
    "window_size = 100\n",
    "window_size_std = 400\n",
    "\n",
    "dates = [\"2025-02-03\", \"2025-02-04\", \"2025-02-05\", \"2025-02-06\", \"2025-02-07\", \"2025-02-08\", \"2025-02-09\"]\n",
    "\n",
    "folder_to_save = \"./experiment_plots\"\n",
    "\n",
    "optimized_color = sns.color_palette(\"Blues\", n_colors=1)[0]  # Main blue shade\n",
    "baseline_color = sns.color_palette(\"Oranges\", n_colors=1)[0]  # Main orange shade\n",
    "\n",
    "\n",
    "theme_style = \"darkgrid\"\n",
    "color_palette_style = \"deep\"\n",
    "palette = sns.color_palette(color_palette_style)\n",
    "sns.set_theme(style=theme_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA GROUPED\n",
    "\n",
    "# prepare optimized data\n",
    "df_list = []\n",
    "for date in dates:\n",
    "    file_path = f'./logs_analysis/{date}/execution_{execution_count}/{date}-optimizedFunction-logs.csv'\n",
    "    \n",
    "    if os.path.exists(file_path):  # Check if file exists to avoid errors\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert timestamp to datetime\n",
    "        df['day'] = df['timestamp'].dt.date  # Extract date to a new column\n",
    "        df['duration_minutes'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60  # Normalize time\n",
    "        df['smoothed_execution_time'] = df['execution_time'].rolling(window=window_size).mean()\n",
    "\n",
    "        df_list.append(df)\n",
    "# Concatenate all dataframes\n",
    "df_all_days_optimized = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "# prepare baseline data\n",
    "df_list = []\n",
    "for date in dates:\n",
    "    file_path = f'./logs_analysis/{date}/execution_{execution_count}/{date}-baselineFunction-logs.csv'\n",
    "    \n",
    "    if os.path.exists(file_path):  # Check if file exists to avoid errors\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'])  # Convert timestamp to datetime\n",
    "        df['day'] = df['timestamp'].dt.date  # Extract date to a new column\n",
    "        df['duration_minutes'] = (df['timestamp'] - df['timestamp'].min()).dt.total_seconds() / 60  # Normalize time\n",
    "        df['smoothed_execution_time'] = df['execution_time'].rolling(window=window_size).mean()\n",
    "\n",
    "        df_list.append(df)\n",
    "# Concatenate all dataframes\n",
    "df_all_days_baseline = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# GROUP ALL DAYS TOGETHER\n",
    "df_optimized_all_days = df_all_days_optimized\n",
    "# Sort the dataframe by duration_minutes to ensure proper rolling calculations\n",
    "df_optimized_all_days = df_optimized_all_days.sort_values(by='duration_minutes')\n",
    "\n",
    "df_baseline_all_days = df_all_days_baseline\n",
    "# Sort the dataframe by duration_minutes to ensure proper rolling calculations\n",
    "df_baseline_all_days = df_baseline_all_days.sort_values(by='duration_minutes')\n",
    "\n",
    "\n",
    "# Compute rolling median & std for optimized function\n",
    "df_optimized_all_days['smoothed_median'] = df_optimized_all_days['execution_time'].rolling(window=window_size, center=True).median()\n",
    "df_optimized_all_days['smoothed_std'] = df_optimized_all_days['execution_time'].rolling(window=window_size_std, center=True).std()\n",
    "\n",
    "# Compute rolling median & std for baseline function\n",
    "df_baseline_all_days['smoothed_median'] = df_baseline_all_days['execution_time'].rolling(window=window_size, center=True).median()\n",
    "df_baseline_all_days['smoothed_std'] = df_baseline_all_days['execution_time'].rolling(window=window_size_std, center=True).std()\n",
    "\n",
    "# Drop NaNs\n",
    "df_optimized_all_days = df_optimized_all_days.dropna(subset=['smoothed_median', 'smoothed_std'])\n",
    "df_baseline_all_days = df_baseline_all_days.dropna(subset=['smoothed_median', 'smoothed_std'])\n",
    "\n",
    "# Get max duration\n",
    "max_duration = max(df_optimized_all_days['duration_minutes'].max(), df_baseline_all_days['duration_minutes'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA FOR EACH METRIC (IMPROVEMENTS)\n",
    "\n",
    "# Dictionary to store improvement values for each metric\n",
    "metric_improvements = {}\n",
    "\n",
    "# READ FILES\n",
    "for date in dates:\n",
    "    data_dir = f\"./logs_analysis/{date}/execution_{execution_count}/\"\n",
    "    file_path = os.path.join(data_dir, f\"table.json\")\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "            for entry in data:\n",
    "                metric = entry[\"Metric\"]\n",
    "                improvement = entry[\"% Improvement\"]  # Keep original value\n",
    "                \n",
    "                if metric not in metric_improvements:\n",
    "                    metric_improvements[metric] = []\n",
    "\n",
    "                # Store the (date, improvement) tuple\n",
    "                metric_improvements[metric].append((date, improvement))\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File for {date} not found, skipping.\")\n",
    "\n",
    "\n",
    "# PREPARE METRICS DATA FOR PLOTS \n",
    "\n",
    "# Convert metric_improvements dictionary into a DataFrame\n",
    "df_list = []\n",
    "for metric, values in metric_improvements.items():\n",
    "    for date, improvement in values:\n",
    "        df_list.append({\"Date\": date, \"Metric\": metric, \"% Improvement\": improvement})\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "\n",
    "# Convert Date column to datetime format for proper plotting\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "# Define relevant metrics for plotting\n",
    "relevant_metrics = [\"Function Execution Time\", \"Download Duration\", \"Linear Regression Execution Time\"]\n",
    "\n",
    "# Filter data for the first plot\n",
    "df_filtered = df[df[\"Metric\"].isin(relevant_metrics)]\n",
    "df_filtered2 = df[df[\"Metric\"].isin([\"Function Execution Time\", \"Linear Regression Execution Time\"])]\n",
    "df_function_execution_time = df[df[\"Metric\"].isin([\"Function Execution Time\"])]\n",
    "\n",
    "# Convert 'dates' list to datetime format before creating the mapping\n",
    "dates_datetime = pd.to_datetime(dates)  # Ensures correct format\n",
    "# Create mapping using datetime keys\n",
    "date_mapping = {date: f\"Day {i+1}\" for i, date in enumerate(sorted(dates_datetime))}\n",
    "# Apply the mapping to the 'day' column\n",
    "df_filtered['day_label'] = df_filtered['Date'].map(date_mapping)\n",
    "df_filtered2['day_label'] = df_filtered2['Date'].map(date_mapping)\n",
    "df_function_execution_time['day_label'] = df_function_execution_time['Date'].map(date_mapping)\n",
    "\n",
    "\n",
    "# Define color palette for consistency\n",
    "num_days = df[\"Date\"].nunique()\n",
    "\n",
    "# Define y axis label\n",
    "y_axis_label = \"% Improvement Over Baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSING BENCHMARK PASSED AND BM >\n",
    "\n",
    "# Define a list to store the benchmark statistics for each file\n",
    "benchmark_stats_list = []\n",
    "\n",
    "# Function to extract benchmark numbers (as already defined)\n",
    "def extract_bm_passed(value):\n",
    "    if isinstance(value, str) and value.startswith(\"BM PASSED:\"):\n",
    "        return float(value.split(\":\")[1].strip())\n",
    "    return None\n",
    "\n",
    "def extract_bm_failed(value):\n",
    "    if isinstance(value, str) and value.startswith(\"BM:\"):\n",
    "        return float(value.split(\":\")[1].split(\">\")[0].strip())\n",
    "    return None\n",
    "\n",
    "def extract_bm_threshold(value):\n",
    "    if isinstance(value, str) and value.startswith(\"BM:\") and \">\" in value:\n",
    "        return float(value.split(\">\")[1].strip())\n",
    "    return None\n",
    "\n",
    "\n",
    "failed_benchmark_count_array = []\n",
    "failed_benchmark_count_percentage_array = []\n",
    "bm_threshold_array = []\n",
    "# Loop through all dates and compute benchmark stats\n",
    "for date in dates:\n",
    "    file_path = f'./logs_analysis/{date}/execution_{execution_count}/{date}-optimizedFunction-logs.csv'\n",
    "    \n",
    "    if os.path.exists(file_path):  # Check if file exists to avoid errors\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Apply benchmark extraction functions\n",
    "        df[\"bm_passed\"] = df[\"benchmark_duration\"].apply(extract_bm_passed)\n",
    "        df[\"bm_failed\"] = df[\"benchmark_duration\"].apply(extract_bm_failed)\n",
    "        bm_threshold = df[\"benchmark_duration\"].apply(extract_bm_threshold).dropna().iloc[0]\n",
    "\n",
    "        # Compute statistics\n",
    "        bm_passed_avg = np.nanmean(df[\"bm_passed\"])\n",
    "        bm_passed_median = np.nanmedian(df[\"bm_passed\"])\n",
    "        bm_failed_avg = np.nanmean(df[\"bm_failed\"])\n",
    "        bm_failed_median = np.nanmedian(df[\"bm_failed\"])\n",
    "\n",
    "        # Append stats as a tuple to the list\n",
    "        benchmark_stats_list.append((date, bm_passed_avg, bm_passed_median, bm_failed_avg, bm_failed_median, bm_threshold))\n",
    "\n",
    "        # Count failed benchmarks\n",
    "        failed_benchmark_count = df[\"bm_failed\"].notna().sum()\n",
    "        failed_benchmark_count_array.append(failed_benchmark_count)\n",
    "        \n",
    "        total_count = len(df)\n",
    "        failed_benchmark_percentage = (failed_benchmark_count / total_count) * 100 if total_count > 0 else 0\n",
    "        failed_benchmark_count_percentage_array.append(failed_benchmark_percentage)\n",
    "\n",
    "        bm_threshold_array.append(bm_threshold)\n",
    "\n",
    "\n",
    "# Convert benchmark stats list to DataFrame\n",
    "stats_df = pd.DataFrame(benchmark_stats_list, columns=[\"Date\", \"bm_passed_avg\", \"bm_passed_median\", \"bm_failed_avg\", \"bm_failed_median\", \"bm_threshold\"])\n",
    "# Ensure that the day_label is added to the stats_df DataFrame\n",
    "stats_df['day_label'] = stats_df['Date'].map(date_mapping)\n",
    "\n",
    "# Melt the DataFrame\n",
    "df_melted_avg = stats_df.melt(id_vars=[\"Date\", \"day_label\"], \n",
    "                          value_vars=[\"bm_passed_avg\", \"bm_failed_avg\", \"bm_threshold\"], \n",
    "                          var_name=\"Metric\", \n",
    "                          value_name=\"Value\")\n",
    "\n",
    "df_melted_median = stats_df.melt(id_vars=[\"Date\", \"day_label\"], \n",
    "                          value_vars=[\"bm_passed_median\", \"bm_failed_median\", \"bm_threshold\"], \n",
    "                          var_name=\"Metric\", \n",
    "                          value_name=\"Value\")\n",
    "\n",
    "df_bm_and_failedavg = stats_df.melt(id_vars=[\"Date\", \"day_label\"], \n",
    "                             value_vars=[\"bm_failed_avg\", \"bm_threshold\"],\n",
    "                             var_name=\"Metric\", \n",
    "                             value_name=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GRAPHS FOR EXECUTIONS: SINGULAR AND GROUPED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIMIZED EXECUTIONS\n",
    "sns.set_theme(style=theme_style)\n",
    "num_days = df_all_days_optimized[\"day\"].nunique()\n",
    "palette = sns.color_palette(\"light:b\", n_colors=num_days+2)[1:-1]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot execution time for different days\n",
    "sns.lineplot(\n",
    "    data=df_all_days_optimized, \n",
    "    x='duration_minutes', \n",
    "    y='smoothed_execution_time', \n",
    "    hue='day', \n",
    "    lw=2, \n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Optimized Execution Time (ms)')\n",
    "plt.title('Optimized Execution Time Over Multiple Days (Smoothed)')\n",
    "\n",
    "# Set x-axis and y-axis to start at 0\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Day\")\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"execution-times-optimized.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE EXECUTIONS\n",
    "sns.set_theme(style=theme_style)\n",
    "# palette = sns.color_palette(\"YlOrBr\", n_colors=df_all_days_optimized[\"day\"].nunique())\n",
    "num_days = df_all_days_optimized[\"day\"].nunique()\n",
    "palette = sns.color_palette(\"light:r\", n_colors=num_days+2)[1:-1]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot execution time for different days\n",
    "sns.lineplot(\n",
    "    data=df_all_days_optimized, \n",
    "    x='duration_minutes', \n",
    "    y='smoothed_execution_time', \n",
    "    hue='day', \n",
    "    lw=2, \n",
    "    palette=palette\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Baseline Execution Time (ms)')\n",
    "plt.title('Baseline Execution Time Over Multiple Days (Smoothed)')\n",
    "\n",
    "# Set x-axis and y-axis to start at 0\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Day\")\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"execution-times-baseline.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE AND OPTIMIZED EXECUTIONS IN ONE GRAPH\n",
    "sns.set_theme(style=theme_style)\n",
    "num_days = df_all_days_optimized[\"day\"].nunique()\n",
    "\n",
    "# Define color palettes\n",
    "optimized_palette = sns.color_palette(\"light:b\", n_colors=num_days+2)[1:-1]\n",
    "baseline_palette = sns.color_palette(\"light:r\", n_colors=num_days+2)[1:-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot optimized execution times\n",
    "optimized_lines = sns.lineplot(\n",
    "    data=df_all_days_optimized,\n",
    "    x='duration_minutes',\n",
    "    y='smoothed_execution_time',\n",
    "    hue='day',\n",
    "    lw=2,\n",
    "    palette=optimized_palette\n",
    ")\n",
    "\n",
    "# Plot baseline execution times\n",
    "baseline_lines = sns.lineplot(\n",
    "    data=df_all_days_baseline,\n",
    "    x='duration_minutes',\n",
    "    y='smoothed_execution_time',\n",
    "    hue='day',\n",
    "    lw=2,\n",
    "    palette=baseline_palette\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Execution Time (ms)')\n",
    "plt.title('Optimized vs. Baseline Execution Time Over Multiple Days (Smoothed)')\n",
    "\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Day\")\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"execution-times-optimized-and-baseline.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# SHOW PLOT\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPED OPTIMIZED RESULTS WITH ERROR BAND\n",
    "\n",
    "# Plot the data\n",
    "sns.set_theme(style=theme_style)\n",
    "palette = sns.color_palette(color_palette_style)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot smoothed median execution time\n",
    "sns.lineplot(\n",
    "    data=df_optimized_all_days,\n",
    "    x='duration_minutes',\n",
    "    y='smoothed_median',\n",
    "    color=palette[0],\n",
    "    label='Optimized Function (Smoothed Median)',\n",
    "    lw=2\n",
    ")\n",
    "\n",
    "# Add error band using standard deviation\n",
    "plt.fill_between(\n",
    "    df_optimized_all_days['duration_minutes'],\n",
    "    df_optimized_all_days['smoothed_median'] - df_optimized_all_days['smoothed_std'],\n",
    "    df_optimized_all_days['smoothed_median'] + df_optimized_all_days['smoothed_std'],\n",
    "    color=palette[0],\n",
    "    alpha=0.2,\n",
    "    label='Standard Deviation'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Execution Time (ms)')\n",
    "plt.title('Smoothed Median Execution Time with Error Band (Optimized Function)')\n",
    "\n",
    "# Set x-axis and y-axis to start at 0\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"grouped-optimized-error-bands.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPED BASELINE RESULTS WITH ERROR BAND\n",
    "\n",
    "# Plot the data\n",
    "sns.set_theme(style=theme_style)\n",
    "palette = sns.color_palette(color_palette_style)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot smoothed median execution time\n",
    "sns.lineplot(\n",
    "    data=df_baseline_all_days,\n",
    "    x='duration_minutes',\n",
    "    y='smoothed_median',\n",
    "    color=palette[1],\n",
    "    label='Optimized Function (Smoothed Median)',\n",
    "    lw=2\n",
    ")\n",
    "\n",
    "# Add error band using standard deviation\n",
    "plt.fill_between(\n",
    "    df_baseline_all_days['duration_minutes'],\n",
    "    df_baseline_all_days['smoothed_median'] - df_baseline_all_days['smoothed_std'],\n",
    "    df_baseline_all_days['smoothed_median'] + df_baseline_all_days['smoothed_std'],\n",
    "    color=palette[1],\n",
    "    alpha=0.2,\n",
    "    label='Standard Deviation'\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Execution Time (ms)')\n",
    "plt.title('Smoothed Median Execution Time with Error Band (Optimized Function)')\n",
    "\n",
    "# Set x-axis and y-axis to start at 0\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"grouped-baseline-error-bands.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPED RESULTS WITH ERROR BANDS\n",
    "\n",
    "# Set up plot\n",
    "sns.set_theme(style=theme_style)\n",
    "palette = sns.color_palette(color_palette_style)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Optimized function\n",
    "sns.lineplot(\n",
    "    data=df_optimized_all_days, x='duration_minutes', y='smoothed_median',\n",
    "    color=palette[0], label='Optimized Function (Smoothed Median)', lw=2\n",
    ")\n",
    "plt.fill_between(\n",
    "    df_optimized_all_days['duration_minutes'],\n",
    "    df_optimized_all_days['smoothed_median'] - df_optimized_all_days['smoothed_std'],\n",
    "    df_optimized_all_days['smoothed_median'] + df_optimized_all_days['smoothed_std'],\n",
    "    color=palette[0], alpha=0.2, label='Optimized Std Dev (Smoothed)'\n",
    ")\n",
    "\n",
    "# Baseline function\n",
    "sns.lineplot(\n",
    "    data=df_baseline_all_days, x='duration_minutes', y='smoothed_median',\n",
    "    color=palette[1], label='Baseline Function (Smoothed Median)', lw=2\n",
    ")\n",
    "plt.fill_between(\n",
    "    df_baseline_all_days['duration_minutes'],\n",
    "    df_baseline_all_days['smoothed_median'] - df_baseline_all_days['smoothed_std'],\n",
    "    df_baseline_all_days['smoothed_median'] + df_baseline_all_days['smoothed_std'],\n",
    "    color=palette[1], alpha=0.2, label='Baseline Std Dev (Smoothed)'\n",
    ")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Execution Time (ms)')\n",
    "plt.title('Execution Time Comparison: Optimized vs. Baseline')\n",
    "\n",
    "# Axis limits\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Legend\n",
    "plt.legend()\n",
    "\n",
    "# Layout adjustment\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"grouped-optimized-and-baseline-error-bands.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVEMENT OVER ALL DAYS\n",
    "\n",
    "# Convert DATA into Pandas DataFrames\n",
    "tables = {}\n",
    "for metric, values in metric_improvements.items():\n",
    "    df = pd.DataFrame(values, columns=[\"Date\", \"% Improvement\"])\n",
    "    df.sort_values(\"Date\", inplace=True)\n",
    "    \n",
    "    # Save table\n",
    "    safe_metric_name = metric.lower().replace(\" \", \"_\")\n",
    "    file_name = f\"table-{safe_metric_name}.json\"\n",
    "    output_path = os.path.join(folder_to_save, file_name)\n",
    "    df.to_json(output_path, orient=\"records\", indent=4)\n",
    "\n",
    "    # Apply formatting (1 decimal place for % Improvement)\n",
    "    styled_df = df.style.format({\"% Improvement\": \"{:.2f}%\"}) \\\n",
    "                        .set_table_styles([{\n",
    "                            'selector': 'thead th', \n",
    "                            'props': [\n",
    "                                ('font-size', '14px'), \n",
    "                                ('text-align', 'center'),\n",
    "                                ('font-weight', 'bold')\n",
    "                            ],\n",
    "                        }]) \\\n",
    "                        .set_properties(**{\n",
    "                            'text-align': 'center',\n",
    "                            'font-size': '12px',\n",
    "                            'padding': '7px',\n",
    "                        }) \\\n",
    "                        .hide(axis=\"index\")\n",
    "    \n",
    "    tables[metric] = styled_df  # Store formatted DataFrame for each metric\n",
    "\n",
    "# DISPLAY TABLES\n",
    "for metric, styled_df in tables.items():\n",
    "    print(f\"\\n{metric}\")\n",
    "    display(styled_df)  # Shows the styled table nicely in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG IMPROVEMENT FOR EACH METRIC\n",
    "\n",
    "# CALCULATE\n",
    "avg_improvements = {\n",
    "    metric: sum(improvement for _, improvement in values) / len(values) \n",
    "    for metric, values in metric_improvements.items() if values\n",
    "}\n",
    "\n",
    "# AVG INTO DATA FRAME\n",
    "avg_df = pd.DataFrame(avg_improvements.items(), columns=[\"Metric\", \"Average % Improvement\"])\n",
    "styled_avg_df = avg_df.style.format({\"Average % Improvement\": \"{:.2f}%\"}) \\\n",
    "                            .set_table_styles([{\n",
    "                                'selector': 'thead th', \n",
    "                                'props': [\n",
    "                                    ('font-size', '14px'), \n",
    "                                    ('text-align', 'center'),\n",
    "                                    ('font-weight', 'bold')\n",
    "                                ],\n",
    "                            }]) \\\n",
    "                            .set_properties(**{\n",
    "                                'text-align': 'center',\n",
    "                                'font-size': '12px',\n",
    "                                'padding': '7px',\n",
    "                            }) \\\n",
    "                            .hide(axis=\"index\")\n",
    "\n",
    "print(\"\\nAverage Improvements Across All Dates\")\n",
    "display(styled_avg_df)\n",
    "\n",
    "# SAVE AVG TABLE\n",
    "file_name = \"table-avg.json\"\n",
    "output_path = os.path.join(folder_to_save, file_name)\n",
    "avg_df.to_json(output_path, orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIAN IMPROVEMENT FOR EACH METRIC\n",
    "median_improvements = {\n",
    "    metric: np.median([improvement for _, improvement in values])  # Using np.median\n",
    "    for metric, values in metric_improvements.items() if values\n",
    "}\n",
    "\n",
    "# CONVERT TO DATAFRAME\n",
    "median_df = pd.DataFrame(median_improvements.items(), columns=[\"Metric\", \"Median % Improvement\"])\n",
    "styled_median_df = median_df.style.format({\"Median % Improvement\": \"{:.2f}%\"}) \\\n",
    "                                  .set_table_styles([{\n",
    "                                      'selector': 'thead th',\n",
    "                                      'props': [\n",
    "                                          ('font-size', '14px'),\n",
    "                                          ('text-align', 'center'),\n",
    "                                          ('font-weight', 'bold')\n",
    "                                      ],\n",
    "                                  }]) \\\n",
    "                                  .set_properties(**{\n",
    "                                      'text-align': 'center',\n",
    "                                      'font-size': '12px',\n",
    "                                      'padding': '7px',\n",
    "                                  }) \\\n",
    "                                  .hide(axis=\"index\")\n",
    "\n",
    "print(\"\\nMedian Improvements Across All Dates\")\n",
    "display(styled_median_df)\n",
    "\n",
    "# SAVE MEDIAN TABLE\n",
    "file_name = \"table-median.json\"\n",
    "output_path = os.path.join(folder_to_save, file_name)\n",
    "median_df.to_json(output_path, orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GRAPHS FOR METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ST FUNC EXEC TIME, DOWNLOAD DURATION, LR EXEC TIME\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_filtered, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:3],\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(y_axis_label)\n",
    "plt.title(\"Improvement Over Time for All Three Metrics\")\n",
    "\n",
    "# Format x-axis ticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Start y-axis at 0\n",
    "# plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Metric\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"improvement_all_metrics.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ND FUNC EXEC TIME vs LR EXECUTION TIME\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_filtered2, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:2],  # Use only the first two colors for consistency\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(y_axis_label)\n",
    "# plt.title(\"Comparison: Function Execution Time vs. Linear Regression Execution Time\")\n",
    "\n",
    "# Format x-axis ticks\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Start y-axis at 0\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Metric\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"improvement_function_exec_vs_linear_regression.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3RD BOXPLOT: FUNC EXEC TIME, DOWNLOAD DURATION, LR EXEC TIME\n",
    "\n",
    "# --- Boxplot for Each Metric ---\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_filtered, \n",
    "    x=\"Metric\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\",  # Assign Metric to hue\n",
    "    palette=palette[:3],  # Use the chosen palette\n",
    "    width=0.5\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "# plt.xlabel(\"Metric\")\n",
    "plt.xlabel(None)\n",
    "# plt.xticks(rotation=25)\n",
    "plt.ylabel(y_axis_label)\n",
    "# plt.title(\"Distribution of % Improvement Over Baseline for Each Metric\")\n",
    "\n",
    "# plt.ylim(bottom=0)\n",
    "# plt.ylim(df_filtered[\"% Improvement\"].min() - 1, df_filtered[\"% Improvement\"].max() + 1)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"boxplot_improvement_by_metric.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4TH FUNCTION EXEC TIME vs FAILED BM COUNT -> COUNT\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# First y-axis (Percentage Improvement)\n",
    "ax1 = plt.gca()  # Get current axis\n",
    "sns.lineplot(\n",
    "    data=df_function_execution_time, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:1],  # Use only the first two colors for consistency\n",
    "    marker=\"o\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Set labels for the first y-axis\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(y_axis_label)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Start y-axis at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Add a second y-axis (Milliseconds)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_function_execution_time[\"day_label\"].unique(), \n",
    "    failed_benchmark_count_array, \n",
    "    color=palette[3], \n",
    "    linestyle=\"--\", \n",
    "    marker=\"s\", \n",
    "    label=\"Failed BM attempts\"\n",
    ")\n",
    "\n",
    "# Set labels for the second y-axis\n",
    "ax2.set_ylabel(\"Count\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(title=\"Metric\", loc=\"lower left\")\n",
    "ax2.legend(title=\"Threshold\", loc=\"lower right\")\n",
    "\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"function_execution-vs-failed_bm_count.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5TH FUNCTION EXEC TIME vs FAILED BM COUNT -> PERCENTAGE\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# First y-axis (Percentage Improvement)\n",
    "ax1 = plt.gca()  # Get current axis\n",
    "sns.lineplot(\n",
    "    data=df_function_execution_time, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:1],  # Use only the first two colors for consistency\n",
    "    marker=\"o\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Set labels for the first y-axis\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(y_axis_label)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Start y-axis at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Add a second y-axis (Milliseconds)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_function_execution_time[\"day_label\"].unique(), \n",
    "    failed_benchmark_count_percentage_array, \n",
    "    color=palette[3], \n",
    "    linestyle=\"--\", \n",
    "    marker=\"s\", \n",
    "    label=\"Failed BM attempts\"\n",
    ")\n",
    "\n",
    "# Set labels for the second y-axis\n",
    "ax2.set_ylabel(\"% Failed BM attempts\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(title=\"Metric\", loc=\"lower left\")\n",
    "ax2.legend(title=\"Threshold\", loc=\"lower right\")\n",
    "\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"function_execution-vs-failed_bm_percentage.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6TH ANALYSE FAILED BM ATTEMPTS\n",
    "\n",
    "for date in dates:\n",
    "    file_path = f'./logs_analysis/{date}/execution_{execution_count}/{date}-optimizedFunction-logs.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert timestamp to datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Determine the experiment start time (earliest timestamp)\n",
    "    experiment_start = df['timestamp'].min()\n",
    "\n",
    "    # Filter passed and failed benchmarks and store their relative minutes\n",
    "    passed_timestamps = []\n",
    "    failed_timestamps = []\n",
    "\n",
    "    # Extract the relative minute for each pass\n",
    "    for _, row in df.iterrows():\n",
    "        if isinstance(row['benchmark_duration'], str):\n",
    "            if row['benchmark_duration'].startswith(\"BM PASSED:\"):\n",
    "                timestamp = (row['timestamp'] - experiment_start).total_seconds() / 60\n",
    "                passed_timestamps.append(timestamp)\n",
    "            elif row['benchmark_duration'].startswith(\"BM:\"):\n",
    "                timestamp = (row['timestamp'] - experiment_start).total_seconds() / 60\n",
    "                failed_timestamps.append(timestamp)\n",
    "\n",
    "    # Create a DataFrame for seaborn visualization\n",
    "    df_plot = pd.DataFrame({\n",
    "        'Timestamp': failed_timestamps,\n",
    "        'Benchmark Type': ['Failed'] * len(failed_timestamps)\n",
    "    })\n",
    "\n",
    "    # Plot with Seaborn\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    sns.scatterplot(\n",
    "        data=df_plot, \n",
    "        x='Timestamp', \n",
    "        y='Benchmark Type', \n",
    "        hue='Benchmark Type', \n",
    "        palette=palette[:1], \n",
    "        s=50\n",
    "    )\n",
    "\n",
    "    # Customize plot\n",
    "    plt.title(f\"Failed Benchmark Attempts on {date}\")\n",
    "    plt.xlabel(\"Relative Time (Minutes)\")\n",
    "    plt.ylabel(\"Benchmark Type\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7TH THRESHOLD, FAILED AVG, % FAILED BM \n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# First y-axis (bm_threshold_array)\n",
    "ax1 = plt.gca()  # Get current axis\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_bm_and_failedavg, \n",
    "    x=\"day_label\", \n",
    "    y=\"Value\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    marker=\"o\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Set labels for the first y-axis\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(\"milliseconds\")\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Start y-axis at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Second y-axis (Failed Benchmark Count)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_filtered2[\"day_label\"].unique(), \n",
    "    failed_benchmark_count_percentage_array, \n",
    "    color=palette[3], \n",
    "    linestyle=\"--\", \n",
    "    marker=\"s\", \n",
    "    label=\"% Failed BM attempts\"\n",
    ")\n",
    "\n",
    "# Set labels for the second y-axis\n",
    "ax2.set_ylabel(\"% Failed BM attempts\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(title=\"Metric\", loc=\"lower left\")\n",
    "ax2.legend(title=\"Threshold\", loc=\"lower right\")\n",
    "\n",
    "ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"improvement_function_exec_vs_linear_regression.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8TH FUNC EXEC TIME vs LR EXEC TIME vs THRESHOLD\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# First y-axis (Percentage Improvement)\n",
    "ax1 = plt.gca()  # Get current axis\n",
    "sns.lineplot(\n",
    "    data=df_filtered2, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:2],  # Use only the first two colors for consistency\n",
    "    marker=\"o\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Set labels for the first y-axis\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(y_axis_label)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Start y-axis at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Add a second y-axis (Milliseconds)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_filtered2[\"day_label\"].unique(), \n",
    "    bm_threshold_array, \n",
    "    color=palette[3], \n",
    "    linestyle=\"--\", \n",
    "    marker=\"s\", \n",
    "    label=\"Threshold (ms)\"\n",
    ")\n",
    "\n",
    "# Set labels for the second y-axis\n",
    "ax2.set_ylabel(\"Threshold (ms)\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(title=\"Metric\", loc=\"upper left\")\n",
    "ax2.legend(title=\"Threshold\", loc=\"upper right\")\n",
    "\n",
    "# ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"function_exec-vs-lr_exec-vs-threshold.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9TH FUNC EXEC TIME vs THRESHOLD\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# First y-axis (Percentage Improvement)\n",
    "ax1 = plt.gca()  # Get current axis\n",
    "sns.lineplot(\n",
    "    data=df_function_execution_time, \n",
    "    x=\"day_label\", \n",
    "    y=\"% Improvement\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:1],  # Use only the first two colors for consistency\n",
    "    marker=\"o\",\n",
    "    ax=ax1\n",
    ")\n",
    "\n",
    "# Set labels for the first y-axis\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(y_axis_label)\n",
    "ax1.tick_params(axis='y')\n",
    "\n",
    "# Start y-axis at 0\n",
    "ax1.set_ylim(bottom=0)\n",
    "\n",
    "# Add a second y-axis (Milliseconds)\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(\n",
    "    df_filtered2[\"day_label\"].unique(), \n",
    "    bm_threshold_array, \n",
    "    color=palette[3], \n",
    "    linestyle=\"--\", \n",
    "    marker=\"s\", \n",
    "    label=\"Threshold (ms)\"\n",
    ")\n",
    "\n",
    "# Set labels for the second y-axis\n",
    "ax2.set_ylabel(\"Threshold (ms)\")\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(title=\"Metric\", loc=\"upper left\")\n",
    "ax2.legend(title=\"Threshold\", loc=\"upper right\")\n",
    "\n",
    "# ax2.set_ylim(bottom=0)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"function_exec-vs-threshold.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passed Avg, Failed Avg, Threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_melted_avg, \n",
    "    x=\"day_label\", \n",
    "    y=\"Value\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:3],\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(\"Benchmark Value\")\n",
    "plt.title(\"Benchmark Metrics Over Time (Passed Avg, Failed Avg, Threshold)\")\n",
    "\n",
    "# Format x-axis ticks\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Metric\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"benchmark_metrics_over_time_avg.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passed Median, Failed Median, Threshold\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(\n",
    "    data=df_melted_median, \n",
    "    x=\"day_label\", \n",
    "    y=\"Value\", \n",
    "    hue=\"Metric\", \n",
    "    lw=2, \n",
    "    palette=palette[:3],\n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(\"Benchmark Value\")\n",
    "plt.title(\"Benchmark Metrics Over Time (Passed Median, Failed Median, Threshold)\")\n",
    "\n",
    "# Add a legend\n",
    "plt.legend(title=\"Metric\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"benchmark_metrics_over_time_median.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP DATA FOR PLOT\n",
    "\n",
    "df_optimized = pd.read_csv(f\"./logs_analysis/2025-02-04/execution_{execution_count}/2025-02-04-optimizedFunction-logs.csv\")\n",
    "df_baseline = pd.read_csv(f\"./logs_analysis/2025-02-04/execution_{execution_count}/2025-02-04-baselineFunction-logs.csv\")\n",
    "\n",
    "# Convert 'timestamp' col to datetime\n",
    "df_optimized['timestamp'] = pd.to_datetime(df_optimized['timestamp'])\n",
    "df_baseline['timestamp'] = pd.to_datetime(df_baseline['timestamp'])\n",
    "# Create col duration in minutes for x-axis\n",
    "df_optimized['duration_minutes'] = (df_optimized['timestamp'] - df_optimized['timestamp'].min()).dt.total_seconds() / 60\n",
    "df_baseline['duration_minutes'] = (df_baseline['timestamp'] - df_baseline['timestamp'].min()).dt.total_seconds() / 60\n",
    "# Create col for smoothed execution time\n",
    "df_optimized['smoothed_execution_time'] = df_optimized['execution_time'].rolling(window=75).mean()\n",
    "df_baseline['smoothed_execution_time'] = df_baseline['execution_time'].rolling(window=75).mean()\n",
    "# Create col for smoothed lr-duration\n",
    "df_optimized = df_optimized[df_optimized['lr_duration'] != 0] # filter out zeros\n",
    "df_optimized['smoothed_lr_duration'] = df_optimized['lr_duration'].rolling(window=75).mean()\n",
    "df_baseline['smoothed_lr_duration'] = df_baseline['lr_duration'].rolling(window=75).mean()\n",
    "\n",
    "df_optimized = df_optimized[df_optimized['lr_duration'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTION TIME ROLLING AVG\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot optimized function execution time\n",
    "sns.lineplot(data=df_optimized, x='duration_minutes', y='smoothed_execution_time', color=palette[0], label='Optimized Function (Smoothed)', lw=2)\n",
    "\n",
    "# Plot baseline function execution time\n",
    "sns.lineplot(data=df_baseline, x='duration_minutes', y='smoothed_execution_time', color=palette[1], label='Baseline Function (Smoothed)', lw=2)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Duration (min)')\n",
    "plt.ylabel('Execution Time (ms)')\n",
    "plt.title('Comparison of Optimized vs Baseline Function Execution Times (Smoothed)')\n",
    "\n",
    "# Set x-axis and y-axis to start at 0\n",
    "plt.xlim(left=0, right=max_duration)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "# Add a legend\n",
    "plt.legend()\n",
    "\n",
    "# Shrink layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# SAVE PLOT\n",
    "plot_filename = os.path.join(folder_to_save, \"2025-02-04-execution-times-rolling-avg.pdf\")\n",
    "plt.savefig(plot_filename)\n",
    "# SHOW PLOT\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvJupyterBSC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
